[toc]

# SFT

## 训练流程

┌────────────────────┐
│     main()         │
└────────┬───────────┘
         ▼
┌────────────────────────────┐
│ 初始化分布式训练环境       │  initialize_global_process_group
└────────┬───────────────────┘
         ▼
┌────────────────────────────┐
│ 构造 DeviceMesh（2个）      │
│ - FSDP Mesh                │
│ - Ulysses Mesh (dp × sp)   │
└────────┬───────────────────┘
         ▼
┌────────────────────────────┐
│ 初始化 FSDPSFTTrainer 实例 │
└────────┬───────────────────┘
         ▼
        [Trainer 内部流程 ↓↓↓]
         ▼
┌────────────────────────────────────┐
│ 1. 加载 Tokenizer + 数据集         │
│ 2. 加载模型 + 应用 LoRA（可选）    │
│ 3. 应用 Flash Attention / Liger    │
│ 4. FSDP 包裹模型 + 构建优化器       │
│ 5. 构建分布式 Dataloader          │
└────────┬──────────────────────────┘
         ▼
┌────────────────────────────┐
│ 开始训练 fit()             │
│ - 遍历 epoch                │
│   - 遍历 batch             │
│     - 计算 loss + backward │
│     - step + clip grad     │
│   - validation             │
│   - 保存 checkpoint        │
└────────────────────────────┘

# RLHF

## 训练数据集

数据集预处理位置：`examples/data_process`

基于规则的奖励函数位置：`verl/utils/reward_score`

训练的数据需要满足如下格式:

~~~json
{
    "data_source": "openai/gsm8k",  # 数据源名称
    "prompt": [
        {
            "role": "user",  # 用户角色
            "content": "question + instruction_following"  # 问题 + 指令
        }
    ],
    "ability": "math",  # 任务能力（此处是数学）
    "reward_model": {
        "style": "rule",  # 奖励模型的风格
        "ground_truth": "solution"  # 答案的最终解答
    },
    "extra_info": {
        "split": "train" or "test",  # 数据集划分（训练集或测试集）
        "index": idx,  # 数据项的索引
        "answer": "raw answer",  # 原始答案（包含可能需要提取的解答）
        "question": "raw question"  # 原始问题
    }
}
~~~

目前支持rlhf训练的数据集

+ openai/gsm8k
+ DigitalLearningGmbH/MATH-lighteval
+ kk
+ hiyouga/geometry3k        目前不支持图片格式



## main_ppo.py

+-------------------------------+
|        启动流程                |
+-------------------------------+
           |
           V
+-------------------------------+
|      打印配置文件              |
+-------------------------------+
           |
           V
+-------------------------------+
|      下载模型文件       |
+-------------------------------+
           |
           V
+-------------------------------+
|      初始化 tokenizer 和 processor  |
|  使用下载的模型文件初始化 tokenizer |
|  使用下载的模型文件初始化 processor（与多模态相关）  |
+-------------------------------+
           |
           V
+-------------------------------+
|      定义工作器类              |
+-------------------------------+
           |
           V
+-------------------------------+
|      定义角色与资源池          |
|  根据角色映射设置资源池规格    |
|  创建角色-工作器映射关系      |
+-------------------------------+
           |
           V
+-------------------------------+
|      设置奖励模型              |
+-------------------------------+
           |
           V
+-------------------------------+
|      创建奖励管理器            |
+-------------------------------+
           |
           V
+-------------------------------+
|      初始化资源池管理器        |
|  使用资源池规格与角色映射创建资源池管理器 |
+-------------------------------+
           |
           V
+-------------------------------+
|      初始化训练器              |
|  使用 `RayPPOTrainer` 初始化训练器 |
|  设置所需的角色、奖励函数与资源池管理器 |
+-------------------------------+
           |
           V
+-------------------------------+
|      启动训练过程              |
|  调用 `trainer.init_workers()` 初始化工作器 |
|  调用 `trainer.fit()` 开始训练过程 |
+-------------------------------+
           |
           V
+-------------------------------+
|           结束                 |
|  完成任务执行                  |
+-------------------------------+

## ray_trainer.py

+---------------------------------------------------+
|                     启动流程                      |
+---------------------------------------------------+
                            |
                            V
+---------------------------------------------------+
|            初始化日志记录器 (Tracking)             |
+---------------------------------------------------+
                            |
                            V
+---------------------------------------------------+
|                  加载训练步骤                      |
|  设置 global_steps 为 0，表示从步骤 0 开始训练  |
+---------------------------------------------------+
                            |
                            V
+---------------------------------------------------+
|                加载检查点 (load_checkpoint)      |
+---------------------------------------------------+
                            |
                            V
+---------------------------------------------------+
|           执行初始验证 (perform validation)        |
+---------------------------------------------------+
                            |
                            V
+---------------------------------------------------+
|                初始化进度条 (tqdm)                |
|  使用 `tqdm` 创建进度条，显示训练的进度          |
+---------------------------------------------------+
                            |
                            V
+---------------------------------------------------+
|                主训练循环 (epochs & batches)      |
|  训练循环：遍历 epochs 和每个 batch               |
+---------------------------------------------------+
                            |
                            V
+---------------------------------------------------+
|             获取和处理每个批次数据 (batch)         |
|  从数据加载器中获取每个批次的数据，并转换为 DataProto 对象|
+---------------------------------------------------+
                            |
                            V
+---------------------------------------------------+
|              数据预处理与生成任务                 |
|  从批次中移除输入相关的字段，为生成任务做准备     |
|  如果有多模态数据，处理不同的数据字段            |
+---------------------------------------------------+
                            |
                            V
+---------------------------------------------------+
|            重复批次并对齐响应                      |
|  对每个批次的数据进行重复，以对齐多个时间步的响应 |
|  使用 `interleave=True` 交错重复数据              |
+---------------------------------------------------+
                            |
                            V
+---------------------------------------------------+
|           平衡有效 token 数量 (batch balance)      |
|  如果配置允许，平衡每个数据并行设备上的有效 token 数量|
+---------------------------------------------------+
                            |
                            V
+---------------------------------------------------+
|          计算每个样本的有效 token 数量            |
|  使用 attention_mask 计算每个样本中的有效 token 数量 |
+---------------------------------------------------+
                            |
                            V
+---------------------------------------------------+
|           计算 log_prob 和参考策略 log_prob       |
|  计算每个批次样本的 log_prob，如果使用参考策略，计算其 log_prob|
+---------------------------------------------------+
                            |
                            V
+---------------------------------------------------+
|             计算价值函数 (Critic)                 |
|  如果使用 critic，计算每个样本的价值函数值        |
+---------------------------------------------------+
                            |
                            V
+---------------------------------------------------+
|           计算奖励 (rewards) 和优势 (advantages)  |
|  使用 reward_fn 计算奖励，并计算每个样本的优势    |
|  如果使用奖励模型，计算奖励模型的分数并与规则奖励结合|
+---------------------------------------------------+
                            |
                            V
+---------------------------------------------------+
|          更新 Critic 模型                         |
|  如果使用 Critic，更新 Critic 模型的权重          |
+---------------------------------------------------+
                            |
                            V
+---------------------------------------------------+
|             更新 Actor 模型                        |
|  在 Critic 模型训练完成后，更新 Actor 模型的权重   |
+---------------------------------------------------+
                            |
                            V
+---------------------------------------------------+
|           执行验证 (validation)                   |
|  如果配置允许，定期执行验证并记录验证指标        |
|  如果到了最后一步或者每隔一定步数执行验证        |
+---------------------------------------------------+
                            |
                            V
+---------------------------------------------------+
|            保存检查点 (save_checkpoint)          |
|  如果配置允许，定期保存当前训练状态的检查点      |
+---------------------------------------------------+
                            |
                            V
+---------------------------------------------------+
|           收集并记录指标 (metrics)                 |
|  计算并记录数据相关的指标、时间相关的指标、吞吐量等|
+---------------------------------------------------+
                            |
                            V
+---------------------------------------------------+
|            更新进度条 (progress bar)              |
|  更新进度条显示当前训练进度                      |
+---------------------------------------------------+
                            |
                            V
+---------------------------------------------------+
|           结束训练（最后一步）                    |
|  如果是最后一步，打印最终验证指标并关闭进度条    |
+---------------------------------------------------+



# Generation

## 整体流程

+-------------------------------+
|        启动流程                |
+-------------------------------+
           |
           V
+-------------------------------+
|       加载配置文件             |
|  使用 Hydra 加载配置文件       |
|  从 `config/generation.yaml` 获取配置 |
+-------------------------------+
           |
           V
+-------------------------------+
|  判断是否已初始化 Ray 集群    |
|  检查是否已经初始化 Ray      |
+-------------------------------+
           |
           +----> 如果已初始化  --> 跳过初始化步骤，继续执行
           |
           +----> 如果未初始化  --> 初始化 Ray 集群，配置运行环境变量
           |
           V
+-------------------------------+
|    加载模型和 Tokenizer        |
|  从本地路径加载预训练模型     |
|  使用 Tokenizer 进行文本编码  |
+-------------------------------+
           |
           V
+-------------------------------+
|       读取数据集 (Parquet)     |
|  从 Parquet 文件读取数据集     |
|  提取数据中的 prompt 列       |
|  将 prompt 转换为 Python 列表   |
+-------------------------------+
           |
           V
+-------------------------------+
|  初始化 Ray 模型 Worker 集群  |
|  初始化 Ray 工作节点（Workers）|
|  为模型推理分配资源池          |
|  启动 Worker 并加载模型       |
+-------------------------------+
           |
           V
+-------------------------------+
|      按批次处理数据集          |
|  将数据集分成多个批次（根据 batch_size）|
|  对每个批次进行文本编码       |
|  确保每个批次符合并行计算要求 |
+-------------------------------+
           |
           V
+-------------------------------+
|     在 Worker 上生成响应       |
|  使用模型生成每个批次的响应   |
|  根据设置的 n_samples 重复生成 |
|  将生成的输出进行解码         |
+-------------------------------+
           |
           V
+-------------------------------+
|      输出文本后处理            |
|  移除生成文本中的 padding     |
|  格式化生成的文本             |
+-------------------------------+
           |
           V
+-------------------------------+
|      保存生成的结果到 Parquet  |
|  将生成的响应（responses）添加到数据集 |
|  保存数据集为新的 Parquet 文件 |
+-------------------------------+
           |
           V
+-------------------------------+
|           结束                 |
|  完成流程，结束执行            |
+-------------------------------+

## 核心类

流程中ray相关类

+  `RayClassWithInitArgs` 提供了工作节点的类型和初始化参数。
+ `RayResourcePool` 提供了计算资源的配置（例如每个节点的 GPU 数量）。
+ `RayWorkerGroup` 使用这两者创建并管理工作节点，执行分布式任务。

# Eval

## 整体流程

+-------------------------------+
|        启动流程                |
+-------------------------------+
           |
           V
+-------------------------------+
|       加载配置文件             |
|  使用 Hydra 加载配置文件       |
|  从 `config/config/evaluation.yaml` 获取配置 |
+-------------------------------+
           |
           V
+-------------------------------+
|       读取 Parquet 文件        |
|  从指定路径读取生成的 Parquet 文件 |
+-------------------------------+
           |
           V
+-------------------------------+
|       提取数据                 |
|  提取数据中的 prompt 列和 response 列 |
|  获取数据源列和奖励模型数据    |
+-------------------------------+
           |
           V
+-------------------------------+
|       选择奖励函数             |
|  根据数据源选择相应的奖励函数 |
|  如果数据源是 'lighteval/MATH'，选择 `math.compute_score` |
+-------------------------------+
           |
           V
+-------------------------------+
|       对每个响应进行评分       |
|  使用选择的奖励函数进行评分   |
|  对每个生成响应与地面真值进行比对 |
+-------------------------------+
           |
           V
+-------------------------------+
|       统计通过率               |
|  如果最大分数为 1，则该响应为正确 |
|  累计通过的正确响应数量       |
+-------------------------------+
           |
           V
+-------------------------------+
|       计算并输出 pass@5       |
|  计算生成正确响应的比例并输出 |
+-------------------------------+
           |
           V
+-------------------------------+
|           结束                 |
|  完成评估流程，结束执行        |
+-------------------------------+

## 奖励函数

奖励函数分为奖励管理类`reward_manager`和奖励计算函数`compute_score`

### reward_manager

奖励管理器分为下面两类：

+ naive：简单的奖励计算方式，适用于不需要复杂的并行处理的场景；
+ prime：适用于大规模并行验证的情况

奖励管理器初始化接受下面三个参数：

+ tokenizer：分词器
+ num_examine：指定在验证过程中，最多打印多少 decoded response 以便进行检查或调试
+ compute_score：用于计算给定响应的评分（`score`）的函数，默认使用 `_default_compute_score` 

### compute_score

`compute_score`函数可以自己编写，默认的`_default_compute_score` 在`verl/utils/reward_score`中

主要功能是从response中提取answer，然后与ground_truth对比获得reward。

目前支持下面一些数据集：

| 数据集名称                           | 描述                                                         | 语言类型 |
| ------------------------------------ | ------------------------------------------------------------ | -------- |
| `openai/gsm8k`                       | 包含 8,500 多道数学问题，旨在评估模型的多步推理能力。        | 英语     |
| `lighteval/MATH`                     | 用于评估数学问题求解模型的能力，包含大量数学题目，难度从基础到复杂不等 | 英语     |
| `DigitalLearningGmbH/MATH-lighteval` | 包含数学竞赛题目，题目来源包括 AMC 10、AMC 12、AIME 等，附有完整的逐步解答 | 英语     |
| `numina_aops_forum`                  | 来源于 AoPS 论坛的数学问题，涉及代数、数论、组合等领域       | 英语     |
| `numina_synthetic_math`              | 合成数学问题，旨在测试模型的数学推理能力                     | 英语     |
| `numina_amc_aime`                    | 包含美国数学竞赛（AMC）和 AIME 的问题，难度适中              | 英语     |
| `numina_synthetic_amc`               | 合成的 AMC 风格问题，供模型训练使用                          | 英语     |
| `numina_cn_k12`                      | 中国 K12 阶段的数学问题，涵盖初中到高中的内容                | 中文     |
| `numina_olympiads`                   | 国际数学奥林匹克（IMO）风格的高级数学问题                    | 英语     |
| `codecontests`                       | 包含来自多种编程竞赛平台（如 CodeForces、CodeChef 等）的编程问题，用于训练 AlphaCode | 英语     |
| `apps`                               | 包含多种编程问题，旨在评估模型的代码生成能力                 | 英语     |
| `codeforces`                         | 包含来自 CodeForces 的编程问题，供模型训练使用               | 英语     |
| `taco`                               | 包含 26,443 道编程问题，强调算法能力，供代码生成模型评估使用 | 英语     |
| `hiyouga/geometry3k`                 | 包含 3,002 道几何问题，附有图形和文本的形式化注释            | 英语     |

目标已有的`compute_score`函数：

+ gsm8k
+ kk
+ math：支持两个math数据集
+ math_verify：支持两个math数据集，使用 math-verify 库提供的数学验证工具进行更精确的验证
+ prime_code：用于评估模型生成的代码在给定测试用例上的正确性
+ prime_math：用于评估模型在数学推理任务中的表现

